{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9219048,"sourceType":"datasetVersion","datasetId":5575089}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-22T07:43:56.849794Z","iopub.execute_input":"2024-08-22T07:43:56.850207Z","iopub.status.idle":"2024-08-22T07:43:57.885154Z","shell.execute_reply.started":"2024-08-22T07:43:56.850174Z","shell.execute_reply":"2024-08-22T07:43:57.883812Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/churn-bigml/churn-bigml-80.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Let's start by loading and inspecting the provided dataset to understand its structure and contents.\nimport pandas as pd\n\n# Load the dataset\nfile_path = '/kaggle/input/churn-bigml/churn-bigml-80.csv'\nchurn_data = pd.read_csv(file_path)\n\n# Display the first few rows of the dataset to understand its structure\nchurn_data.head(), churn_data.info()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T07:43:57.887346Z","iopub.execute_input":"2024-08-22T07:43:57.887802Z","iopub.status.idle":"2024-08-22T07:43:57.957646Z","shell.execute_reply.started":"2024-08-22T07:43:57.887770Z","shell.execute_reply":"2024-08-22T07:43:57.956548Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2666 entries, 0 to 2665\nData columns (total 20 columns):\n #   Column                  Non-Null Count  Dtype  \n---  ------                  --------------  -----  \n 0   State                   2666 non-null   object \n 1   Account length          2666 non-null   int64  \n 2   Area code               2666 non-null   int64  \n 3   International plan      2666 non-null   object \n 4   Voice mail plan         2666 non-null   object \n 5   Number vmail messages   2666 non-null   int64  \n 6   Total day minutes       2666 non-null   float64\n 7   Total day calls         2666 non-null   int64  \n 8   Total day charge        2666 non-null   float64\n 9   Total eve minutes       2666 non-null   float64\n 10  Total eve calls         2666 non-null   int64  \n 11  Total eve charge        2666 non-null   float64\n 12  Total night minutes     2666 non-null   float64\n 13  Total night calls       2666 non-null   int64  \n 14  Total night charge      2666 non-null   float64\n 15  Total intl minutes      2666 non-null   float64\n 16  Total intl calls        2666 non-null   int64  \n 17  Total intl charge       2666 non-null   float64\n 18  Customer service calls  2666 non-null   int64  \n 19  Churn                   2666 non-null   bool   \ndtypes: bool(1), float64(8), int64(8), object(3)\nmemory usage: 398.5+ KB\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(  State  Account length  Area code International plan Voice mail plan  \\\n 0    KS             128        415                 No             Yes   \n 1    OH             107        415                 No             Yes   \n 2    NJ             137        415                 No              No   \n 3    OH              84        408                Yes              No   \n 4    OK              75        415                Yes              No   \n \n    Number vmail messages  Total day minutes  Total day calls  \\\n 0                     25              265.1              110   \n 1                     26              161.6              123   \n 2                      0              243.4              114   \n 3                      0              299.4               71   \n 4                      0              166.7              113   \n \n    Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n 0             45.07              197.4               99             16.78   \n 1             27.47              195.5              103             16.62   \n 2             41.38              121.2              110             10.30   \n 3             50.90               61.9               88              5.26   \n 4             28.34              148.3              122             12.61   \n \n    Total night minutes  Total night calls  Total night charge  \\\n 0                244.7                 91               11.01   \n 1                254.4                103               11.45   \n 2                162.6                104                7.32   \n 3                196.9                 89                8.86   \n 4                186.9                121                8.41   \n \n    Total intl minutes  Total intl calls  Total intl charge  \\\n 0                10.0                 3               2.70   \n 1                13.7                 3               3.70   \n 2                12.2                 5               3.29   \n 3                 6.6                 7               1.78   \n 4                10.1                 3               2.73   \n \n    Customer service calls  Churn  \n 0                       1  False  \n 1                       1  False  \n 2                       0  False  \n 3                       2  False  \n 4                       3  False  ,\n None)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Separate features and target variable\nX = churn_data.drop(columns='Churn')\ny = churn_data['Churn']\n\n# Identify categorical and numerical columns\ncategorical_cols = ['State', 'International plan', 'Voice mail plan']\nnumerical_cols = X.columns.difference(categorical_cols)\n\n# Preprocessing pipeline for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Preprocessing pipeline for numerical data\nnumerical_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())\n])\n\n# Combine preprocessing steps into a single ColumnTransformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n# Define the models we want to train\nlogreg_model = Pipeline(steps=[('preprocessor', preprocessor),\n                               ('classifier', LogisticRegression(max_iter=1000))])\n\nrf_model = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('classifier', RandomForestClassifier(random_state=42))])\n\n# Train the models\nlogreg_model.fit(X_train, y_train)\nrf_model.fit(X_train, y_train)\n\n# Evaluate models on the test set\nlogreg_preds = logreg_model.predict(X_test)\nrf_preds = rf_model.predict(X_test)\n\nlogreg_report = classification_report(y_test, logreg_preds)\nrf_report = classification_report(y_test, rf_preds)\n\nlogreg_auc = roc_auc_score(y_test, logreg_model.predict_proba(X_test)[:, 1])\nrf_auc = roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n\nlogreg_report, rf_report, logreg_auc, rf_auc\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T07:43:57.959225Z","iopub.execute_input":"2024-08-22T07:43:57.959525Z","iopub.status.idle":"2024-08-22T07:44:00.386474Z","shell.execute_reply.started":"2024-08-22T07:43:57.959500Z","shell.execute_reply":"2024-08-22T07:44:00.385156Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"('              precision    recall  f1-score   support\\n\\n       False       0.88      0.96      0.92       684\\n        True       0.50      0.24      0.33       116\\n\\n    accuracy                           0.85       800\\n   macro avg       0.69      0.60      0.62       800\\nweighted avg       0.83      0.85      0.83       800\\n',\n '              precision    recall  f1-score   support\\n\\n       False       0.93      1.00      0.96       684\\n        True       0.97      0.58      0.72       116\\n\\n    accuracy                           0.94       800\\n   macro avg       0.95      0.79      0.84       800\\nweighted avg       0.94      0.94      0.93       800\\n',\n 0.7764544262956241,\n 0.8818499193385764)"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate models on the test set\nlogreg_preds = logreg_model.predict(X_test)\nrf_preds = rf_model.predict(X_test)\n\nlogreg_report = classification_report(y_test, logreg_preds)\nrf_report = classification_report(y_test, rf_preds)\n\nlogreg_auc = roc_auc_score(y_test, logreg_model.predict_proba(X_test)[:, 1])\nrf_auc = roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])\n\nprint(\"Logistic Regression Report:\\n\", logreg_report)\nprint(\"Random Forest Report:\\n\", rf_report)\nprint(\"Logistic Regression ROC-AUC Score:\", logreg_auc)\nprint(\"Random Forest ROC-AUC Score:\", rf_auc)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T07:44:00.389436Z","iopub.execute_input":"2024-08-22T07:44:00.389860Z","iopub.status.idle":"2024-08-22T07:44:00.502968Z","shell.execute_reply.started":"2024-08-22T07:44:00.389824Z","shell.execute_reply":"2024-08-22T07:44:00.501931Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Logistic Regression Report:\n               precision    recall  f1-score   support\n\n       False       0.88      0.96      0.92       684\n        True       0.50      0.24      0.33       116\n\n    accuracy                           0.85       800\n   macro avg       0.69      0.60      0.62       800\nweighted avg       0.83      0.85      0.83       800\n\nRandom Forest Report:\n               precision    recall  f1-score   support\n\n       False       0.93      1.00      0.96       684\n        True       0.97      0.58      0.72       116\n\n    accuracy                           0.94       800\n   macro avg       0.95      0.79      0.84       800\nweighted avg       0.94      0.94      0.93       800\n\nLogistic Regression ROC-AUC Score: 0.7764544262956241\nRandom Forest ROC-AUC Score: 0.8818499193385764\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the parameter grid for GridSearchCV\nparam_grid = {\n    'classifier__n_estimators': [100, 200, 300],\n    'classifier__max_depth': [None, 10, 20, 30],\n    'classifier__min_samples_split': [2, 5, 10],\n    'classifier__min_samples_leaf': [1, 2, 4]\n}\n\n# Initialize GridSearchCV\ngrid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n\n# Perform grid search\ngrid_search.fit(X_train, y_train)\n\n# Print the best parameters found\nprint(\"Best parameters found: \", grid_search.best_params_)\n\n# Evaluate the best model\nbest_rf_model = grid_search.best_estimator_\nbest_rf_preds = best_rf_model.predict(X_test)\nbest_rf_report = classification_report(y_test, best_rf_preds)\nbest_rf_auc = roc_auc_score(y_test, best_rf_model.predict_proba(X_test)[:, 1])\n\nprint(\"Best Random Forest Model Report:\\n\", best_rf_report)\nprint(\"Best Random Forest ROC-AUC Score:\", best_rf_auc)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T07:44:00.504412Z","iopub.execute_input":"2024-08-22T07:44:00.504738Z","iopub.status.idle":"2024-08-22T07:47:39.990683Z","shell.execute_reply.started":"2024-08-22T07:44:00.504710Z","shell.execute_reply":"2024-08-22T07:47:39.989218Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Best parameters found:  {'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 100}\nBest Random Forest Model Report:\n               precision    recall  f1-score   support\n\n       False       0.93      1.00      0.96       684\n        True       0.97      0.57      0.72       116\n\n    accuracy                           0.94       800\n   macro avg       0.95      0.78      0.84       800\nweighted avg       0.94      0.94      0.93       800\n\nBest Random Forest ROC-AUC Score: 0.8900610002016536\n","output_type":"stream"}]},{"cell_type":"code","source":"import joblib\n# Save the best model\njoblib.dump(best_rf_model, 'best_rf_model.pkl')\n\n# To load and use the model later:\n# loaded_model = joblib.load('best_rf_model.pkl')\n# predictions = loaded_model.predict(new_data)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T07:47:39.992481Z","iopub.execute_input":"2024-08-22T07:47:39.992929Z","iopub.status.idle":"2024-08-22T07:47:40.060970Z","shell.execute_reply.started":"2024-08-22T07:47:39.992883Z","shell.execute_reply":"2024-08-22T07:47:40.059955Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['best_rf_model.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"from flask import Flask, request, jsonify\nimport joblib\n\n# Load the model\nmodel = joblib.load('best_rf_model.pkl')\n\n# Initialize Flask app\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    # Get data from POST request\n    data = request.get_json()\n    # Convert to DataFrame\n    df = pd.DataFrame(data)\n    # Make prediction\n    prediction = model.predict(df)\n    # Return the prediction as JSON\n    return jsonify({'prediction': prediction.tolist()})\n\nif __name__ == '__main__':\n    app.run(debug=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T07:47:40.062203Z","iopub.execute_input":"2024-08-22T07:47:40.062521Z","iopub.status.idle":"2024-08-22T07:47:41.105530Z","shell.execute_reply.started":"2024-08-22T07:47:40.062493Z","shell.execute_reply":"2024-08-22T07:47:41.104118Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":" * Serving Flask app '__main__'\n * Debug mode: on\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1042, in launch_instance\n    app.initialize(argv)\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 113, in inner\n    return method(app, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 654, in initialize\n    self.init_sockets()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n    return self._try_bind_socket(s, port)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n  File \"/opt/conda/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 302, in bind\n    super().bind(addr)\n  File \"zmq/backend/cython/socket.pyx\", line 564, in zmq.backend.cython.socket.Socket.bind\n  File \"zmq/backend/cython/checkrc.pxd\", line 28, in zmq.backend.cython.checkrc._check_rc\nzmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:59367')\n","output_type":"stream"},{"traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"],"ename":"SystemExit","evalue":"1","output_type":"error"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n","output_type":"stream"}]}]}